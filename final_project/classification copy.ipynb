{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "\n",
      "Random Forest Results:\n",
      "\n",
      "SVM Results:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9172413793103448"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def classify_activity(features_path, features_list, classification_method):\n",
    "    # Load data\n",
    "    data = pd.read_csv(features_path)\n",
    "    X = data[features_list]\n",
    "    y = data['Activity']\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Select classifier based on the specified method\n",
    "    if classification_method == 'decision_tree':\n",
    "        classifier = DecisionTreeClassifier(random_state=42)\n",
    "    elif classification_method == 'random_forest':\n",
    "        classifier = RandomForestClassifier(random_state=42)\n",
    "    elif classification_method == 'svm':\n",
    "        classifier = SVC(random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid classification method\")\n",
    "    \n",
    "    # Train the classifier and predict\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Display confusion matrix\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "    #             xticklabels=classifier.classes_, yticklabels=classifier.classes_)\n",
    "    # plt.xlabel(\"Predicted Label\")\n",
    "    # plt.ylabel(\"True Label\")\n",
    "    # plt.title(f\"Confusion Matrix - {classification_method.capitalize()}\")\n",
    "    #plt.show()\n",
    "    \n",
    "    #print(f\"\\nAccuracy ({classification_method.capitalize()}):\\n\", accuracy)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Example usage:\n",
    "print(\"Decision Tree Results:\")\n",
    "classify_activity('features_window4.csv', ['mean_x', 'std_x', 'mean_y', 'std_y', 'mean_z', 'std_z', 'median_x', 'median_y', 'median_z', 'root_mean_square_x', 'root_mean_square_y', 'root_mean_square_z'], 'decision_tree')\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "classify_activity('features.csv', ['mean_x', 'std_x', 'mean_y', 'std_y', 'mean_z', 'std_z'], 'random_forest')\n",
    "\n",
    "print(\"\\nSVM Results:\")\n",
    "classify_activity('features.csv', ['mean_x', 'std_x', 'mean_y', 'std_y', 'mean_z', 'std_z'], 'svm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def classify_with_sfs(features_path, features_list, time_interval):\n",
    "    # Load data\n",
    "    data = pd.read_csv(features_path)\n",
    "    X = data[features_list]\n",
    "    y = data['Activity']\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize classifier (Decision Tree in this case)\n",
    "    classifier = DecisionTreeClassifier(random_state=42)\n",
    "    \n",
    "    # Sequential Feature Selector to find the best feature subset\n",
    "    sfs = SequentialFeatureSelector(classifier, n_features_to_select=\"auto\", direction=\"forward\", scoring=\"accuracy\", cv=None)\n",
    "    sfs.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best feature subset\n",
    "    best_features = list(X_train.columns[sfs.get_support()])\n",
    "    print(\"Best feature subset:\", best_features)\n",
    "    \n",
    "    # Train the classifier on the selected features\n",
    "    classifier.fit(X_train[best_features], y_train)\n",
    "    y_pred = classifier.predict(X_test[best_features])\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"\\nAccuracy with best feature subset:\", accuracy)\n",
    "    \n",
    "    return best_features, accuracy\n",
    "\n",
    "# Example usage with the best time interval and initial feature set\n",
    "best_features, accuracy = classify_with_sfs('features_window4.csv', \n",
    "                                            ['mean_x', 'std_x', 'mean_y', 'std_y', 'mean_z', 'std_z', 'median_x', 'median_y', 'median_z', 'root_mean_square_x', 'root_mean_square_y', 'root_mean_square_z'], \n",
    "                                            time_interval=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "\n",
      "Selected feature: mean_x, Accuracy: 0.8586206896551725\n",
      "Selected feature: mean_z, Accuracy: 0.906896551724138\n",
      "Selected feature: root_mean_square_y, Accuracy: 0.9344827586206896\n",
      "Selected feature: median_z, Accuracy: 0.9448275862068966\n",
      "Selected feature: median_x, Accuracy: 0.9586206896551724\n",
      "Random Forest Results:\n",
      "\n",
      "Selected feature: mean_x, Accuracy: 0.8586206896551725\n",
      "Selected feature: median_z, Accuracy: 0.9310344827586207\n",
      "Selected feature: mean_y, Accuracy: 0.9448275862068966\n",
      "Selected feature: mean_z, Accuracy: 0.9586206896551724\n",
      "Selected feature: std_z, Accuracy: 0.9620689655172414\n",
      "SVM Results:\n",
      "\n",
      "Selected feature: median_x, Accuracy: 0.896551724137931\n",
      "Selected feature: mean_z, Accuracy: 0.9241379310344827\n",
      "Selected feature: std_y, Accuracy: 0.9379310344827586\n"
     ]
    }
   ],
   "source": [
    "def sequential_feature_selection(features_path, candidate_features, classification_method='decision_tree'):\n",
    "    best_features = []\n",
    "    best_accuracy = 0\n",
    "    feature_accuracies = {}\n",
    "\n",
    "    for i in range(len(candidate_features)):\n",
    "        best_feature_in_round = None\n",
    "        for feature in candidate_features:\n",
    "            if feature in best_features:\n",
    "                continue\n",
    "            # Test this feature combination\n",
    "            current_features = best_features + [feature]\n",
    "            accuracy = classify_activity(features_path, current_features, classification_method)\n",
    "            \n",
    "            # Track best feature in this round\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_feature_in_round = feature\n",
    "\n",
    "        # If no improvement, stop the selection\n",
    "        if best_feature_in_round is None:\n",
    "            break\n",
    "        \n",
    "        # Update best features and accuracy\n",
    "        best_features.append(best_feature_in_round)\n",
    "        feature_accuracies[tuple(best_features)] = best_accuracy\n",
    "        print(f\"Selected feature: {best_feature_in_round}, Accuracy: {best_accuracy}\")\n",
    "        \n",
    "candidate_features = ['mean_x', 'std_x', 'median_x', 'root_mean_square_x', 'mean_y', 'std_y', 'median_y', 'root_mean_square_y', 'mean_z', 'std_z', 'median_z', 'root_mean_square_z']\n",
    "\n",
    "\n",
    "print(\"Decision Tree Results:\\n\")\n",
    "sequential_feature_selection('features_window4.csv', candidate_features, classification_method='decision_tree')\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Random Forest Results:\\n\")\n",
    "sequential_feature_selection('features_window4.csv', candidate_features, classification_method='random_forest')\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"SVM Results:\\n\")\n",
    "sequential_feature_selection('features_window4.csv', candidate_features, classification_method='svm')\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['mean_y', 'std_y', 'mean_z', 'std_z', 'median_x', 'root_mean_square_z']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
